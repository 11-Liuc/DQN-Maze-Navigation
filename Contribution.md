# 📋 课题 5：基于 DQN 的迷宫寻路智能体 - 小组分工表

本项目由 5 人小组合作完成，旨在掌握深度 Q 网络（DQN）的设计与优化 。

## 1. 成员职责与交付物清单

| 成员角色 | 核心代码交付 (文件名) | 报告撰写分工 (章节) | 关键职责说明 |
| :--- | :--- | :--- | :--- |
| **组长 **<br>项目集成 | `requirements.txt`<br>`main.py` (入口)<br>`maze_env.py` (改进)<br>`dqn_model.py` (改进)<br>`dqn_agent.py` (改进)<br>`memory.py` (改进)<br>`final_report.docx` | **3.** **系统需求与设计**<br>**4.2 泛化能力改进** | 1. **负责 GitHub 代码管理与版本控制**。<br>2. 制定代码规范，负责最终代码的合并与逻辑校验。<br>3. 汇总全组文字，完成实验报告的最终整合。<br>4. **实现泛化能力改进方案**：<br>&nbsp;&nbsp;&nbsp;- 增强状态表示（2维→10维，加入8方向障碍物检测）<br>&nbsp;&nbsp;&nbsp;- 扩展网络容量（128→256→256→128，参数量提升6倍）<br>&nbsp;&nbsp;&nbsp;- 增加经验回放容量（10K→50K）<br>&nbsp;&nbsp;&nbsp;- 训练验证：5x5随机地图成功率提升至60%+，7x7达到60%，撞墙次数从90+降至0 。 |
| **同学 B**<br>环境工程师 | `maze_env.py` <br>`maze_maps.json`<br>`visualizer.py` | **1. 引言** <br/> | 1. 编写迷宫环境（支持动态大小，默认 10x10），定义状态空间与动作空间 。<br>2. 设计奖励函数：终点 +10，碰撞 -5，步长 -0.1 。<br>3. 实现智能体移动轨迹的可视化展示 。 |
| **同学 C**<br>算法工程师 | `dqn_model.py` <br>`dqn_agent.py`<br>`memory.py` | **2. 相关技术与理论基础** <br> | 1. 使用 PyTorch 构建深度 Q 网络 。<br>2. 实现经验回放缓冲区与目标网络稳定机制 。<br>3. 编写 $\epsilon$-贪婪策略的衰减逻辑 。 |
| **同学 D**<br>训练专家 | `train_manager.py`<br>`log_analysis.py`<br>`training_logs.csv` | **4. 实验与结果分析**  | 1. 执行超参数调优（学习率 0.001、$\gamma$ 0.99 等） 。<br>2. 记录训练数据，绘制每 100 步的平均奖励曲线 。<br>3. 撰写超参数调优报告 。 |
| **同学 E**<br>首席汇报人 | `presentation.pptx`<br>`demo_video.mp4`<br>`references.bib` | **5. 总结与展望** <br>**6. 参考文献**  | 1. **负责最终 PPT 制作与现场答辩演示**。<br>2. 收集各成员素材，录制智能体寻路动图或视频展示成果。<br>3. 统一全组文档视觉风格，整理项目参考文献。 |

## 2. 技术规范
* **开发环境**：Python 3.10+ 。
* **核心框架**：Gymnasium, PyTorch 。
* **路径规范**：所有代码涉及文件读写需支持跨平台运行。
